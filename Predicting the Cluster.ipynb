{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the scaler and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.84333333 3.054      3.75866667 1.19866667]\n",
      "[0.68112222 0.18675067 3.09242489 0.57853156]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "print(scaler.mean_)\n",
    "print(scaler.var_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.01457897,  0.84230679, -1.30487835, -1.25512862])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_clustering = joblib.load('iris_clustering.pkl')\n",
    "iris_clustering.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_clustering.n_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the cluster of the new data I don't use the .predict method. I calculate the distance manually so I cant customize the dictance calculation.\n",
    "From the given centers we build the function to classify new data to one of the clusters. We can breakdown the steps into :\n",
    "\n",
    "1. Transform the new data using the same transformation with the original/train data. \n",
    "2. Calculate the distances between the data and every center points. \n",
    "3. Classify the data to the nearest cluster (minimal distance from the center point).\n",
    "\n",
    "I use euclidean, you can use different distance (ie: Mahalanobis, Minkowski, etc) from **scipy.spatial.distance** or you can define your own distance function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "def auto_clustering(sepal_length,sepal_width, petal_length, petal_width):\n",
    "    x = [sepal_length,sepal_width, petal_length, petal_width]\n",
    "    x_mean = scaler.mean_\n",
    "    x_var = scaler.var_\n",
    "    for i in range(4):\n",
    "        x[i] = (x[i]-x_mean[i])/x_var[i]\n",
    "    #if you don't wanna customize the distance, the following command might be enough\n",
    "    #return(iris_clustering.predict([x]))\n",
    "    \n",
    "    center_0 = iris_clustering.cluster_centers_[0]\n",
    "    center_1 = iris_clustering.cluster_centers_[1]    \n",
    "    center_2 = iris_clustering.cluster_centers_[2]\n",
    "    dist = {\n",
    "    'Cluster 0' : euclidean(center_0, x),\n",
    "    'Cluster 1' : euclidean(center_1, x),\n",
    "    'Cluster 2' : euclidean(center_2, x)\n",
    "    }\n",
    "    return(min(dist, key=dist.get))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
